# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-05-02 07:14+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, no-wrap
msgid "ebernard"
msgstr ""

#. type: YAML Front Matter: date
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, no-wrap
msgid "2020-04-21"
msgstr ""

#. type: YAML Front Matter: layout
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, no-wrap
msgid "post"
msgstr ""

#. type: YAML Front Matter: synopsis
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, no-wrap
msgid "Understand when and how to use the Quarkus IO thread and its influence on microbenchmarks."
msgstr ""

#. type: YAML Front Matter: tags
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, no-wrap
msgid "performance"
msgstr ""

#. type: YAML Front Matter: title
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, no-wrap
msgid "A IO thread and a worker thread walk into a bar: a microbenchmark story"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:17
#, fuzzy
msgid "A competitor recently published a microbenchmark comparing the performance of their stack to Quarkus.  The Quarkus team feels this microbenchmark shouldn’t be taken at face value because it wasn’t making a like-to-like comparison leading to incorrect conclusions.  Both of the two frameworks under comparison support reactive processing.  Reactive processing enables running the business logic directly on the _IO thread_, which ultimately performs better in microbenchmark focusing on response time and concurrency.  The microbenchmark should have been written so that both frameworks (or neither framework) obtain this benefit.  Anyway, this turns out to be a very interesting topic and good information for Quarkus users, so read on."
msgstr "Un competidor publicó recientemente un microbenchmark comparando el rendimiento de su pila con Quarkus. El equipo de Quarkus considera que este microbenchmark no debería tomarse al pie de la letra porque no estaba haciendo una comparación de igual a igual, lo que lleva a conclusiones incorrectas. Ambos frameworks comparados soportan el procesamiento reactivo. El procesamiento reactivo permite ejecutar la lógica de negocio directamente en el _hilo IO_, que en última instancia se comporta mejor en el microbenchmark centrado en el tiempo de respuesta y la concurrencia. El microbenchmark debería haberse escrito de forma que ambos marcos (o ninguno) obtuvieran este beneficio. De todos modos, esto resulta ser un tema muy interesante y una buena información para los usuarios de Quarkus, así que sigue leyendo."

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:18
#, fuzzy, no-wrap
msgid "tl; dr;"
msgstr "tl; dr;"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:22
#, fuzzy
msgid "Quarkus https://quarkus.io/blog/runtime-performance/[has great performance] for both imperative and reactive workloads.  It’s because Quarkus is itself based on Eclipse Vert.x, a mature top performing reactive framework, in such a way that allows you to layer, mix and match the IO paradigm that best fits your use-case."
msgstr "Quarkus  link:https://quarkus.io/blog/runtime-performance/[tiene un gran rendimiento] tanto para cargas de trabajo imperativas como reactivas. Esto se debe a que Quarkus se basa en Eclipse Vert.x, un marco reactivo maduro de alto rendimiento, de tal manera que le permite superponer, mezclar y combinar el paradigma IO que mejor se adapte a su caso de uso."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:24
#, fuzzy
msgid "If you have a REST scenario well suited to run _purely on the IO thread_, add a Vert.x Reactive Route using https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] and your app will get better performance than using Quarkus RESTEasy."
msgstr "Si tienes un escenario REST muy adecuado para ejecutarse _puramente en el hilo IO_, añade una ruta reactiva Vert.x utilizando  link:https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] y tu aplicación obtendrá un mejor rendimiento que utilizando Quarkus RESTEasy."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:28
#, fuzzy
msgid "We ran this low-work REST + validation competitor-written microbenchmark which features no blocking operation, just returning static data.  When using Quarkus Reactive Routes to run Quarkus _purely on the IO thread_, **we observed 2.6x times the requests/sec and 30% less memory usage (RSS)** than running with Quarkus RESTEasy (which mixes IO thread and worker thread).  But that’s on a microbenchmark purpose built to this specific scenario (more on that later)."
msgstr "Ejecutamos este microbenchmark de REST de bajo trabajo + validación escrito por un competidor que no presenta ninguna operación de bloqueo, sólo devuelve datos estáticos. Cuando se utiliza Quarkus Reactive Routes para ejecutar Quarkus _puramente en el_ hilo IO, *observamos 2,6 veces más solicitudes/seg y un 30% menos de uso de memoria (RSS)* que ejecutando con Quarkus RESTEasy (que mezcla el hilo IO y el hilo trabajador). Pero eso es en un microbenchmark construido a propósito para este escenario específico (más sobre eso más adelante)."

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:29
#, no-wrap
msgid "throughput.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:31
#, fuzzy, no-wrap
msgid "More interesting read"
msgstr "Más información sobre el tema"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:35
#, fuzzy
msgid "The microbenchmark itself is uninteresting, but it is a good demonstrator of a phenomenon that can happen in reactive stacks.  Let’s use it as a vehicle to learn more about Quarkus and its reactive engine."
msgstr "El microbenchmark en sí mismo no es interesante, pero es un buen demostrador de un fenómeno que puede ocurrir en las pilas reactivas. Vamos a utilizarlo como vehículo para aprender más sobre Quarkus y su motor reactivo."

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:36
#, fuzzy, no-wrap
msgid "Imperative and Reactive: the elevator pitch"
msgstr "Imperativo y reactivo: el discurso del ascensor"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:40
#, fuzzy
msgid "This blog post does not explain the fundamental differences between the imperative execution model and the reactive execution model.  However, to understand why we see so much difference in the mentioned microbenchmark, we need some notions."
msgstr "Esta entrada del blog no explica las diferencias fundamentales entre el modelo de ejecución imperativo y el modelo de ejecución reactivo. Sin embargo, para entender por qué vemos tanta diferencia en el microbenchmark mencionado, necesitamos algunas nociones."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:49
#, fuzzy
msgid "In general, Java web applications use imperative programming combined with blocking IO operations.  This is incredibly popular because it is easier to reason about the code.  _Things_ get executed sequentially.  To make sure one request is not affected by another, they are run on different threads.  When your workload needs to interact with a database or another remote service, it relies on blocking IO.  The thread is blocked waiting for the answer.  Other requests running on different threads are not slowed down significantly.  But this means one thread for every concurrent request, which limits the overall concurrency."
msgstr "En general, las aplicaciones web de Java utilizan la programación imperativa combinada con operaciones IO de bloqueo. Esto es increíblemente popular porque es más fácil razonar sobre el código. _Las cosas_ se ejecutan secuencialmente. Para asegurarse de que una solicitud no se ve afectada por otra, se ejecutan en diferentes hilos. Cuando su carga de trabajo necesita interactuar con una base de datos u otro servicio remoto, se basa en el bloqueo de IO. El hilo se bloquea esperando la respuesta. Otras peticiones que se ejecutan en hilos diferentes no se ralentizan significativamente. Pero esto significa un hilo para cada solicitud concurrente, lo que limita la concurrencia global."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:64
#, fuzzy
msgid "On the other side, the reactive execution model embraces asynchronous development models and non blocking IOs.  With this model, multiple requests can be handled by the same thread.  When the processing of a request cannot make progress anymore (because it requests a remote service, or interacts with a database), it uses non blocking IO.  This releases the thread immediately, which can then be used to serve another request.  When the result of the IO operation is available, the processing of the request is restored and continues its execution.  This model enables the usage of the _IO thread_ to handle multiple requests.  There are two significant benefits.  First, the response time is smaller because it does not have to jump to another thread.  Second, it reduces memory consumption as it decreases the usage of threads.  The reactive model uses the hardware resources more efficiently, but... there is a significant drawback.  If the processing of a request starts to block, this gets real bad.  No other request can be handled.  To avoid this, you need to learn how to write non blocking code, how to structure asynchronous processing, and how to use non blocking IOs.  It's a paradigm shift."
msgstr "Por otro lado, el modelo de ejecución reactiva abarca los modelos de desarrollo asíncronos y los IOs no bloqueantes. Con este modelo, múltiples peticiones pueden ser manejadas por el mismo hilo. Cuando el procesamiento de una petición ya no puede progresar (porque solicita un servicio remoto, o interactúa con una base de datos), utiliza IO no bloqueantes. Esto libera el hilo inmediatamente, que puede ser utilizado para servir otra petición. Cuando el resultado de la operación IO está disponible, el procesamiento de la petición se restablece y continúa su ejecución. Este modelo permite el uso del hilo _IO_ para manejar múltiples peticiones. Hay dos beneficios significativos. En primer lugar, el tiempo de respuesta es menor porque no tiene que saltar a otro hilo. En segundo lugar, reduce el consumo de memoria al disminuir el uso de hilos. El modelo reactivo utiliza los recursos de hardware de forma más eficiente, pero... hay un inconveniente importante. Si el procesamiento de una solicitud comienza a bloquearse, esto se pone muy mal. No se puede atender ninguna otra petición. Para evitar esto, tienes que aprender a escribir código no bloqueante, cómo estructurar el procesamiento asíncrono, y cómo usar IOs no bloqueantes. Es un cambio de paradigma."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:68
#, fuzzy
msgid "In Quarkus, we want to make the shift as easy as possible.  However, we have observed that the majority of user applications are written using the imperative model.  That is why, when the user application uses JAX-RS, Quarkus defaults to execute the (imperative) workload to a _worker thread_."
msgstr "En Quarkus, queremos que el cambio sea lo más fácil posible. Sin embargo, hemos observado que la mayoría de las aplicaciones de usuario están escritas utilizando el modelo imperativo. Por eso, cuando la aplicación de usuario utiliza JAX-RS, Quarkus ejecuta por defecto la carga de trabajo (imperativa) a un _hilo de trabajo_."

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:69
#, fuzzy, no-wrap
msgid "Hello world microbenchmark: IO thread or worker thread?"
msgstr "Hola mundo microbenchmark: ¿Hilo IO o hilo worker?"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:74
#, fuzzy
msgid "Back to the competitor’s microbenchmark, we have a REST endpoint doing some trivial processing and some equally trivial validation.  Pretty much no meaningful business work.  This is the Hello World of REST for all intents and purposes."
msgstr "Volviendo al microbenchmark de la competencia, tenemos un punto final REST que realiza un procesamiento trivial y una validación igualmente trivial. Prácticamente no hay trabajo comercial significativo. Este es el Hola Mundo de REST para todos los propósitos."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:79
#, fuzzy
msgid "When you run the microbenchmark with Quarkus RESTEasy, the request is handled by the reactive engine on the _IO thread_ but then the processing work is handed over to a second thread from the _worker thread pool_.  That’s called _dispatch_.  When your microbenchmark does as little as Hello World, then the dispatch overhead is proportionally big.  The dispatch overhead is not visible in most (real life) applications but is very visible in artificial constructs like microbenchmarks."
msgstr "Cuando se ejecuta el microbenchmark con Quarkus RESTEasy, el motor reactivo se encarga de la solicitud en el _hilo IO_, pero luego el trabajo de procesamiento se entrega a un segundo hilo del _grupo de hilos de trabajo_. Esto se llama _despacho_. Cuando tu microbenchmark hace algo tan pequeño como Hello World, entonces la sobrecarga de despacho es proporcionalmente grande. La sobrecarga de despacho no es visible en la mayoría de las aplicaciones (de la vida real), pero es muy visible en construcciones artificiales como los microchmarks."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:83
#, fuzzy
msgid "The competitor’s stack, however, runs all the request operations on the IO thread by default.  So what this microbenchmark was actually comparing is just the cost of dispatching to the worker thread pool.  And frankly (according to the competitor's numbers) and in spite of this extra dispatch work, Quarkus did very very well achieving ~95% of the competitor’s throughput today! I say today because we are always improving upon performance, and in fact we expect to see further gains in the soon to be released 1.4 release."
msgstr "La pila de la competencia, sin embargo, ejecuta todas las operaciones de petición en el hilo IO por defecto. Así que lo que este microbenchmark estaba comparando en realidad es sólo el coste de enviar al grupo de hilos de trabajo. Y francamente (según los números del competidor) y a pesar de este trabajo extra de envío, Quarkus lo hizo muy bien, logrando un ~95% del rendimiento del competidor hoy. Digo hoy porque siempre estamos mejorando el rendimiento, y de hecho esperamos ver más ganancias en la próxima versión 1.4."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:85
#, fuzzy, no-wrap
msgid "*When compared at a disadvantage (dispatching to a worker thread), Quarkus is nevertheless almost as fast in throughput.*\n"
msgstr "*Cuando se compara en desventaja (despachando a un hilo de trabajo), Quarkus es sin embargo casi tan rápido en rendimiento.*"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:90
#, fuzzy
msgid "… But wait, Quarkus can also avoid the dispatch altogether and run operations on the IO Thread.  This is a more accurate comparison to how the competitor' stack was configured to do as in both case, it is the user's responsibility to ask for a dispatch if and when needed by the application.  To compare apples to apples, let’s use https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] backed by Eclipse Vert.x.  In this model, operations are run on the IO thread by default."
msgstr "... Pero espera, Quarkus también puede evitar el envío por completo y ejecutar las operaciones en el hilo IO. Esta es una comparación más precisa de cómo se configuró la pila de la competencia, ya que en ambos casos, es responsabilidad del usuario pedir un despacho si y cuando lo necesita la aplicación. Para comparar manzanas con manzanas, usemos  link:https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] respaldado por Eclipse Vert.x. En este modelo, las operaciones se ejecutan en el thread IO por defecto."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:95
#, fuzzy
msgid "@ApplicationScoped public class MyDeclarativeRoutes {"
msgstr "@ApplicationScoped public class MyDeclarativeRoutes {"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:98
#, fuzzy, no-wrap
msgid ""
"  @Inject\n"
"  Validator validator;\n"
msgstr ""
"<pre>@Inject\n"
"Validador validador;</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:111
#, fuzzy, no-wrap
msgid ""
"  @Route(path = \"/hello/:name\", methods = HttpMethod.GET)\n"
"  void greetings(RoutingExchange ex) {\n"
"    RequestWrapper requestWrapper = new RequestWrapper(ex.getParam(\"name\").orElse(\"world\"));\n"
"    Set<ConstraintViolation<RequestWrapper>> violations = validator.validate(requestWrapper));\n"
"    if( violations.size() == 0) {\n"
"      ex.ok(\"hello \" + requestWrapper.name);\n"
"    } else {\n"
"      StringBuilder validationError = new StringBuilder();\n"
"      violations.stream().forEach(violation -> validationError.append(violation.getMessage()));\n"
"      ex.response().setStatusCode(400).end(validationError.toString());\n"
"    }\n"
"  }\n"
msgstr ""
"<pre>@Route(path = \"/hello/:name\", methods = HttpMethod.GET)\n"
"void saludos(RoutingExchange ex) {\n"
"  RequestWrapper requestWrapper = new RequestWrapper(ex.getParam(\"nombre\").orElse(\"mundo\"));\n"
"  Set&lt;ConstraintViolation&lt;RequestWrapper&gt;&gt; violations = validator.validate(requestWrapper));\n"
"  if( violations.size() == 0) {\n"
"    ex.ok(\"hola \" + requestWrapper.name);\n"
"  } else {\n"
"    StringBuilder validationError = new StringBuilder();\n"
"    violations.stream().forEach(violation -&gt; validationError.append(violation.getMessage()));\n"
"    ex.response().setStatusCode(400).end(validationError.toString());\n"
"  }\n"
"}</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:115
#, fuzzy, no-wrap
msgid ""
"  private class RequestWrapper {\n"
"    @NotBlank\n"
"    public String name;\n"
msgstr ""
"<pre>private class RequestWrapper {\n"
"  @NotBlank\n"
"  public String name;</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:120
#, fuzzy, no-wrap
msgid ""
"    public RequestWrapper(String name) {\n"
"      this.name = name;\n"
"    }\n"
"  }\n"
msgstr ""
"<pre>  public RequestWrapper(String name) {\n"
"    this.name = name;\n"
"  }\n"
"}</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:122
#, fuzzy
msgid "}"
msgstr "}"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:125
#, fuzzy
msgid "This is not very different from your JAX-RS equivalent."
msgstr "Esto no es muy diferente de su equivalente JAX-RS."

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:126
#, fuzzy, no-wrap
msgid "Throughput Numbers"
msgstr "Números de rendimiento"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:129
#, fuzzy
msgid "We ran the microbenchmark application in a docker container constrained to reflect a typical resource allocation to a container orchestrated by Kubernetes:"
msgstr "Ejecutamos la aplicación de microbenchmark en un contenedor docker restringido para reflejar una asignación de recursos típica a un contenedor orquestado por Kubernetes:"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:131
#, fuzzy
msgid "4 CPU"
msgstr "4 CPU"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:132
#, fuzzy
msgid "256 MB of RAM"
msgstr "256 MB de RAM"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:133
#, fuzzy
msgid "and `-Xmx128m` heap usage for the Java process"
msgstr "y `-Xmx128m` uso del heap para el proceso Java"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:139
#, fuzzy
msgid "We saw that Quarkus using Reactive Routes ran 2.6 times the requests/sec.  2.6 times! It makes sense! Remember the application code virtually does nothing, so the dispatch cost is comparatively high.  If you were to write a more real life workload (maybe even having a blocking operation like a JPA access and therefore forcing a dispatch), then the results would be very different.  Context matters!"
msgstr "Vimos que Quarkus usando Rutas Reactivas ejecutaba 2,6 veces las peticiones/seg. ¡2,6 veces! ¡Tiene sentido! Recuerda que el código de la aplicación prácticamente no hace nada, por lo que el coste de envío es comparativamente alto. Si escribieras una carga de trabajo más real (tal vez incluso teniendo una operación de bloqueo como un acceso JPA y por lo tanto forzando un despacho), entonces los resultados serían muy diferentes. El contexto es importante."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:141
#, fuzzy
msgid "You can find code and how to reproduce the microbenchmark https://github.com/johnaohara/quarkus-iothread-workerpool/tree/1.3.1.Final[here on GitHub]."
msgstr "Puedes encontrar el código y cómo reproducir el microbenchmark  link:https://github.com/johnaohara/quarkus-iothread-workerpool/tree/1.3.1.Final[aquí en GitHub]."

#. type: Block title
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:142
#, fuzzy, no-wrap
msgid "Microbenchmark results comparing Quarkus dispatching to a worker thread vs running purely on the IO thread"
msgstr "Resultados de microcomprobación comparando el envío de Quarkus a un hilo de trabajo frente a la ejecución exclusiva en el hilo de E/S"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:146
#, fuzzy, no-wrap
msgid "Quarkus - 1.3.1.Final - 4 CPU's"
msgstr "Quarkus - 1.3.1.Final - 4 CPU's"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:147
#, fuzzy, no-wrap
msgid "Worker thread"
msgstr "Hilo de trabajo"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:148
#, fuzzy, no-wrap
msgid "IO thread"
msgstr "Hilo IO"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:150
#, fuzzy, no-wrap
msgid "Ratio"
msgstr "Ratio"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:151
#, fuzzy, no-wrap
msgid "Mean Start Time to First Request (ms) footnote:[‘Mean Start Time to First Request’ was measured using an application built as an UberJar]"
msgstr "Tiempo medio de inicio hasta la primera solicitud (ms) <sup class=\"footnote\">[ link:#_footnotedef_1[1, id=_footnoteref_1, role=footnote, title=View footnote.]</sup>]"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:152
#, fuzzy, no-wrap
msgid "993.9"
msgstr "993.9"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:153
#, fuzzy, no-wrap
msgid "868.3"
msgstr "868.3"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:155
#, fuzzy, no-wrap
msgid "87.4%"
msgstr "87.4%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:156
#, fuzzy, no-wrap
msgid "Max RSS (MB)"
msgstr "RSS máximo (MB)"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:157
#, fuzzy, no-wrap
msgid "138.8"
msgstr "138.8"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:158
#, fuzzy, no-wrap
msgid "97.9"
msgstr "97.9"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:160
#, fuzzy, no-wrap
msgid "70.5%"
msgstr "70.5%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:161
#, fuzzy, no-wrap
msgid "Max Throughput (req/sec)"
msgstr "Rendimiento máximo (req/seg)"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:162
#, fuzzy, no-wrap
msgid "46,172.2"
msgstr "46,172.2"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:163
#, fuzzy, no-wrap
msgid "123,520.4"
msgstr "123,520.4"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:165
#, fuzzy, no-wrap
msgid "267.5%"
msgstr "267.5%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:166
#, fuzzy, no-wrap
msgid "Max Req/Sec/MB"
msgstr "Requisito/segundo máximo/MB"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:167
#, fuzzy, no-wrap
msgid "332.7"
msgstr "332.7"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:168
#, fuzzy, no-wrap
msgid "1,262.1"
msgstr "1,262.1"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:169
#, fuzzy, no-wrap
msgid "379.4%"
msgstr "379.4%"

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:171
#, no-wrap
msgid "throughput-percentile.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:174
#, fuzzy, no-wrap
msgid "*In a fair comparison (purely remaining on the IO thread - no dispatch), Quarkus more than double its throughput.*\n"
msgstr "*En una comparación justa (permaneciendo puramente en el hilo IO - sin despacho), Quarkus más que duplica su rendimiento.*"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:179
#, fuzzy
msgid "As the generated load tends towards the maximum throughput of the system under test, the response time experienced by the client increases exponentially.  So the best system (for the workload) has a vertical line as far to the right as possible.  Equally important is to have as flat a line as possible for the longest time.  You do not want the response time to degrade before the system reaches maximum throughput."
msgstr "A medida que la carga generada tiende hacia el rendimiento máximo del sistema bajo prueba, el tiempo de respuesta experimentado por el cliente aumenta exponencialmente. Por tanto, el mejor sistema (para la carga de trabajo) tiene una línea vertical lo más a la derecha posible. Igualmente importante es tener una línea lo más plana posible durante el mayor tiempo. No quieres que el tiempo de respuesta se degrade antes de que el sistema alcance el máximo rendimiento."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:184
#, fuzzy
msgid "By the way, in the competitor microbenchmark Quarkus is shown as consuming more RSS (more RAM).This is also explained by the worker thread pool being operated whereas the competitor did not have a worker thread pool.  The Quarkus Reactive Routes solution (on a pure IO event run) shows a 30% RSS usage reduction."
msgstr "Por cierto, en el microbenchmark de la competencia, Quarkus aparece consumiendo más RSS (más RAM), lo que también se explica por el funcionamiento del grupo de hilos de trabajo, mientras que el competidor no tenía un grupo de hilos de trabajo. La solución Quarkus Reactive Routes (en una ejecución de eventos IO pura) muestra una reducción del 30% en el uso de RSS."

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:185
#, no-wrap
msgid "rss.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:189
#, fuzzy
msgid "In this graph, the lower, the better.  We see that the pure IO thread solution manages to increase throughput with little to no change to the memory usage (RSS), that's very good!"
msgstr "En este gráfico, cuanto más bajo, mejor. Vemos que la solución de hilos IO puros consigue aumentar el rendimiento con poco o ningún cambio en el uso de la memoria (RSS), ¡eso es muy bueno!"

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:190
#, fuzzy, no-wrap
msgid "Conclusion"
msgstr "Conclusión"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:196
#, fuzzy
msgid "Quarkus offers you the ability to safely run blocking operations, run non blocking operations on the IO thread or mix both models.  The Quarkus team takes performance very seriously and we see Quarkus as offering great numbers whether you use the imperative or reactive models.  In more realistic workloads, the dispatch cost would be much less significant, you would not see such drastic differences between the two approaches.  As usual, test as close to your real application as possible."
msgstr "Quarkus le ofrece la posibilidad de ejecutar con seguridad operaciones de bloqueo, ejecutar operaciones no bloqueantes en el hilo IO o mezclar ambos modelos. El equipo de Quarkus se toma el rendimiento muy en serio y vemos que Quarkus ofrece grandes números tanto si se utilizan los modelos imperativos como los reactivos. En cargas de trabajo más realistas, el coste de despacho sería mucho menos significativo, no verías diferencias tan drásticas entre los dos enfoques. Como siempre, haz pruebas lo más cerca posible de tu aplicación real."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:203
#, fuzzy
msgid "Mystery solved.  Benchmarks are hard, challenge them.  But the moral of the story is that in all bad comes some good.  We’ve now learned how to run Quarkus applications entirely on the IO thread.  And how in some situations that can make a big difference.  Remember, don’t block! In fact, Quarkus https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[can warn you if you do so].  Oh and we also learned that Quarkus is so fast, it can even beat itself ;p"
msgstr "Misterio resuelto. Los puntos de referencia son difíciles, desafíenlos. Pero la moraleja de la historia es que en todo lo malo hay algo bueno. Ahora hemos aprendido cómo ejecutar aplicaciones Quarkus completamente en el hilo IO. Y cómo en algunas situaciones eso puede suponer una gran diferencia. Recuerda, ¡no bloquees! De hecho, Quarkus  link:https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[puede advertirte si lo haces]. Ah, y también hemos aprendido que Quarkus es tan rápido que incluso puede ganarse a sí mismo ;p"

#, fuzzy
#~ msgid "---\n"
#~ msgstr "---\n"

#, fuzzy
#~ msgid ""
#~ "layout: post\n"
#~ "title: 'A IO thread and a worker thread walk into a bar: a microbenchmark story'\n"
#~ "date: 2020-04-21\n"
#~ "tags: performance\n"
#~ "synopsis: Understand when and how to use the Quarkus IO thread and its influence on microbenchmarks.\n"
#~ "author: ebernard\n"
#~ "---\n"
#~ msgstr ""
#~ "layout: post\n"
#~ "title: Un hilo IO y un hilo worker entran en un bar: la historia de un microbenchmark\n"
#~ "date: 2020-04-21\n"
#~ "tags: performance\n"
#~ "synopsis: Entender cuándo y cómo utilizar el hilo IO de Quarkus y su influencia en los microbenchmarks.\n"
#~ "author: ebernard\n"
#~ "---\n"
