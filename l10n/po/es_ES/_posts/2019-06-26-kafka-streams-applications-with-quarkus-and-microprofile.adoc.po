# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-05-02 07:14+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, no-wrap
msgid "gmorling"
msgstr ""

#. type: YAML Front Matter: date
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, no-wrap
msgid "2019-06-26"
msgstr ""

#. type: YAML Front Matter: layout
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, no-wrap
msgid "post"
msgstr ""

#. type: YAML Front Matter: tags
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, no-wrap
msgid "kafka microprofile"
msgstr ""

#. type: YAML Front Matter: title
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "Building Kafka Streams applications with Quarkus and Eclipse MicroProfile"
msgstr ""
"layout: post\n"
"title: 'Construyendo aplicaciones Kafka Streams con Quarkus y Eclipse MicroProfile'\n"
"date: 2019-06-26\n"
"tags: kafka microprofile\n"
"author: gmorling\n"
"---\n"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:12
#, fuzzy
msgid "https://kafka.apache.org/documentation/streams/[Kafka Streams] is a very popular solution for implementing stream processing applications based on Apache Kafka.  It lets you do typical data streaming tasks like filtering and transforming messages, joining multiple Kafka topics, performing (stateful) calculations, grouping and aggregating values in time windows and much more."
msgstr "link:https://kafka.apache.org/documentation/streams/[Kafka Streams] es una solución muy popular para implementar aplicaciones de procesamiento de flujos basadas en Apache Kafka. Permite realizar tareas típicas de streaming de datos como filtrar y transformar mensajes, unir múltiples temas de Kafka, realizar cálculos (con estado), agrupar y agregar valores en ventanas de tiempo y mucho más."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:17
#, fuzzy
msgid "Unlike other streaming query engines that run on specific processing clusters, Kafka Streams is a client library.  This means a (Java) application is needed which starts and runs the streaming pipeline, reading from and writing to the Apache Kafka cluster."
msgstr "A diferencia de otros motores de consulta de streaming que se ejecutan en clusters de procesamiento específicos, Kafka Streams es una biblioteca cliente. Esto significa que se necesita una aplicación (Java) que inicie y ejecute la tubería de streaming, leyendo y escribiendo en el clúster de Apache Kafka."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:20
#, fuzzy
msgid "In this blog post we'll discuss how the combination of Quarkus and https://microprofile.io/[Eclipse MicroProfile] is a great foundation for implementing Kafka Streams applications, running on the JVM and as native code compiled ahead of time via https://www.graalvm.org/[GraalVM]."
msgstr "En esta entrada del blog discutiremos cómo la combinación de Quarkus y  link:https://microprofile.io/[Eclipse MicroProfile] es una gran base para la implementación de aplicaciones Kafka Streams, que se ejecutan en la JVM y como código nativo compilado por adelantado a través de  link:https://www.graalvm.org/[GraalVM]."

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:21
#, fuzzy, no-wrap
msgid "The Quarkus extension for Kafka Streams"
msgstr "La extensión de Quarkus para Kafka Streams"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:25
#, fuzzy
msgid "As of version 0.17.0, Quarkus comes with link:/guides/kafka-streams[an extension] for building Kafka Streams applications.  To create a new Quarkus project with this extension, run the following:"
msgstr "A partir de la versión 0.17.0, Quarkus viene con  link:/guides/kafka-streams[una extensión] para construir aplicaciones Kafka Streams. Para crear un nuevo proyecto de Quarkus con esta extensión, ejecute lo siguiente:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:32
#, no-wrap
msgid ""
"mvn io.quarkus:quarkus-maven-plugin:0.17.0:create \\\n"
"   -DprojectGroupId=org.acme \\\n"
"   -DprojectArtifactId=kafka-streams-quickstart-example \\\n"
"   -Dextensions=\"kafka-streams\"\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:36
#, fuzzy
msgid "This will set up a new project, adding the dependency to the Quarkus Kafka Streams extension, which in turn will pull in Kafka Streams and all its dependencies."
msgstr "Esto creará un nuevo proyecto, añadiendo la dependencia a la extensión Quarkus Kafka Streams, que a su vez tirará de Kafka Streams y todas sus dependencias."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:40
#, fuzzy
msgid "If you've worked with Kafka Streams before, the implementation of a data streaming pipeline will look very familiar to you.  You first build up a `Topology` and then create a `KafkaStreams` instance.  For starting and stopping the latter, Quarkus' `StartupEvent` and `ShutdownEvent` classes come in handy."
msgstr "Si ya has trabajado con Kafka Streams, la implementación de un pipeline de streaming de datos te resultará muy familiar. Primero construyes un `Topology` y luego creas una instancia de `KafkaStreams`. Para iniciar y detener esta última, las clases `StartupEvent` y `ShutdownEvent` de Quarkus son muy útiles."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:42
#, fuzzy
msgid "Overall, the structure of a Kafka Streams pipeline running on Quarkus will look like so:"
msgstr "En general, la estructura de una tubería de Kafka Streams que se ejecuta en Quarkus se verá así:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:47
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:240
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MyStreamingPipeline {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:49
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:182
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:245
#, no-wrap
msgid "    private KafkaStreams streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:54
#, no-wrap
msgid ""
"    void onStart(@Observes StartupEvent event) {\n"
"        // set up Kafka Streams config, e.g. sourced from application.properties\n"
"        Properties props = new Properties();\n"
"        // props.put(..., ...);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:58
#, no-wrap
msgid ""
"        // set up the stream topology\n"
"        StreamsBuilder builder = new StreamsBuilder();\n"
"        // builder.stream(...)\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:62
#, no-wrap
msgid ""
"        streams = new KafkaStreams(builder.build(), props);\n"
"        streams.start();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:67
#, no-wrap
msgid ""
"    void onStop(@Observes ShutdownEvent event) {\n"
"        streams.close();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:73
#, fuzzy
msgid "For the very common requirement that you'd like to serialize and deserialize Java types used in the streaming pipeline into/from JSON (e.g. when materializing them in a state store), the Quarkus Kafka Streams extension provides the class `io.quarkus.kafka.client.serialization.JsonbSerde`.  It's a `Serde` implementation based on JSON-B:"
msgstr "Para el requisito muy común de querer serializar y deserializar los tipos Java utilizados en la tubería de streaming en/desde JSON (por ejemplo, cuando se materializan en un almacén de estado), la extensión Quarkus Kafka Streams proporciona la clase `io.quarkus.kafka.client.serialization.JsonbSerde`. Es una implementación de `Serde` basada en JSON-B:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:78
#, no-wrap
msgid ""
"...\n"
"JsonbSerde<WeatherStation> weatherStationSerde = new JsonbSerde<>(WeatherStation.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:84
#, no-wrap
msgid ""
"GlobalKTable<Integer, WeatherStation> stations = builder.globalTable(\n"
"    \"weather-stations\",\n"
"    Consumed.with(Serdes.Integer(), weatherStationSerde)\n"
");\n"
"...\n"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:86
#, fuzzy, no-wrap
msgid "Running Native"
msgstr "Nativo de la carrera"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:91
#, fuzzy
msgid "Based on Kafka's notion of topic partitioning, Kafka Streams applications can easily be scaled out: the load will be shared amongst multiple instances of the application, each processing just a subset of the partitions of the input topic(s)."
msgstr "Basándose en la noción de partición de temas de Kafka, las aplicaciones de Kafka Streams pueden escalarse fácilmente: la carga se repartirá entre múltiples instancias de la aplicación, cada una de las cuales procesará sólo un subconjunto de las particiones de los temas de entrada."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:96
#, fuzzy
msgid "Running Quarkus applications in native code via GraalVM comes in very handy for that: besides the very fast start-up time, the applications will use significantly less memory when compiled to native code.  This lets you spin up many instances of a Quarkus-based Kafka Streams pipeline in parallel, in a very memory-efficient way."
msgstr "Ejecutar aplicaciones Quarkus en código nativo a través de GraalVM es muy útil para eso: además del tiempo de inicio muy rápido, las aplicaciones utilizarán significativamente menos memoria cuando se compilan en código nativo. Esto le permite hacer girar muchas instancias de una tubería de Kafka Streams basada en Quarkus en paralelo, de una manera muy eficiente de memoria."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:101
#, fuzzy
msgid "The extension takes care of everything needed for building native Kafka Streams applications, for instance it makes sure that the right RocksDB native libraries are added to the application image.  All you need to do is to specify the `enableJni` option for the Quarkus Maven plug-in, allowing those native libraries to be invoked via JNI:"
msgstr "La extensión se encarga de todo lo necesario para construir aplicaciones nativas de Kafka Streams, por ejemplo, se asegura de que las bibliotecas nativas de RocksDB adecuadas se añadan a la imagen de la aplicación. Todo lo que necesitas hacer es especificar la opción `enableJni` para el plugin de Quarkus Maven, permitiendo que esas bibliotecas nativas sean invocadas vía JNI:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:118
#, no-wrap
msgid ""
"<plugin>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-maven-plugin</artifactId>\n"
"    <executions>\n"
"        <execution>\n"
"            <goals>\n"
"                <goal>native-image</goal>\n"
"            </goals>\n"
"            <configuration>\n"
"                <enableJni>true</enableJni>\n"
"            </configuration>\n"
"        </execution>\n"
"    </executions>\n"
"</plugin>\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:123
#, fuzzy
msgid "When using the `JsonbSerde` for unmarshalling JSON into corresponding Java objects, those types must be marked with the `@RegisterForReflection` annotation, so that they can to be instantiated reflectively by JSON-B in native mode:"
msgstr "Cuando se utiliza `JsonbSerde` para convertir JSON en los correspondientes objetos Java, estos tipos deben estar marcados con la anotación `@RegisterForReflection`, para que puedan ser instanciados reflexivamente por JSON-B en modo nativo:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:128
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:132
#, no-wrap
msgid ""
"    public int id;\n"
"    public String name;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:136
#, fuzzy
msgid "Then build the application using the `native` profile (note this requires GraalVM to be installed on your system; refer to the Quarkus link:/guides/building-native-image[native image] guide to learn more):"
msgstr "A continuación, construya la aplicación utilizando el perfil `native` (tenga en cuenta que esto requiere que GraalVM esté instalado en su sistema; consulte la guía de  link:/guides/building-native-image[imágenes nativas] de Quarkus para obtener más información):"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:140
#, no-wrap
msgid "mvn clean package -f aggregator/pom.xml -Pnative\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:147
#, fuzzy
msgid "Finding the right amount of memory needed for running the application can require some testing.  E.g. observe CPU load and run the native binary with the `-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+VerboseGC` options in order to gain insight into how often garbage collection kicks in.  If you started the application with not enough heap space, you'll typically observe that GC is happening very frequently, causing increased CPU load."
msgstr "Encontrar la cantidad correcta de memoria necesaria para ejecutar la aplicación puede requerir algunas pruebas. Por ejemplo, observe la carga de la CPU y ejecute el binario nativo con las opciones de `-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+VerboseGC` para obtener información sobre la frecuencia con la que se activa la recolección de basura. Si has iniciado la aplicación sin suficiente espacio en la pila, normalmente observarás que la GC se produce con mucha frecuencia, provocando un aumento de la carga de la CPU."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:154
#, fuzzy
msgid "To give an example, for the https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart[streaming pipeline] discussed in the Kafka Streams extension guide, a heap size of 32 MB (`-Xmx32m`) works very well, resulting in less than 50 MB memory needed by the process in total (RSS, resident set size).  Note that this number also contains the memory needed for the HTTP endpoint defined in that example, which is used for answering interactive queries via REST."
msgstr "Para dar un ejemplo, para el  link:https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart[pipeline de streaming] discutido en la guía de extensión de Kafka Streams, un tamaño de heap de 32 MB ( `-Xmx32m`) funciona muy bien, lo que resulta en menos de 50 MB de memoria necesaria para el proceso en total (RSS, tamaño del conjunto residente). Ten en cuenta que este número también contiene la memoria necesaria para el endpoint HTTP definido en ese ejemplo, que se utiliza para responder a las consultas interactivas vía REST."

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:155
#, fuzzy, no-wrap
msgid "Gaining Operational Insight"
msgstr "Obtención de información operativa"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:161
#, fuzzy
msgid "One of the nice things about Quarkus is that it comes with support for all the Eclipse MicroProfile APIs.  They help to address common requirements when building microservices, such as https://microprofile.io/project/eclipse/microprofile-health[health checks] (\"Is my application running and ready to handle requests?\")  and https://microprofile.io/project/eclipse/microprofile-metrics[metrics] (\"What's the throughput of my application?\", \"How many requests has it processed?\" etc.)."
msgstr "Una de las cosas buenas de Quarkus es que viene con soporte para todas las APIs de Eclipse MicroProfile. Ayudan a abordar los requisitos comunes cuando se construyen microservicios, como las  link:https://microprofile.io/project/eclipse/microprofile-health[comprobaciones de salud] (\"¿Está mi aplicación en funcionamiento y preparada para atender solicitudes?\") y las  link:https://microprofile.io/project/eclipse/microprofile-metrics[métricas] (\"¿Cuál es el rendimiento de mi aplicación?\", \"¿Cuántas solicitudes ha procesado?\", etc.)."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:165
#, fuzzy
msgid "Based on those APIs, it just requires a little bit of coding to implement health checks and metrics for a Kafka Streams application.  You can add the right dependencies by running:"
msgstr "Basado en esas APIs, sólo requiere un poco de codificación para implementar controles de salud y métricas para una aplicación Kafka Streams. Puedes añadir las dependencias adecuadas ejecutando:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:169
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"health,metrics\"\n"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:171
#, fuzzy, no-wrap
msgid "Healthchecks"
msgstr "Controles de salud"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:174
#, fuzzy
msgid "Then creating the health check is as simple as adding the following to the pipeline implementation:"
msgstr "A continuación, la creación de la comprobación de la salud es tan simple como añadir lo siguiente a la implementación de la tubería:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:180
#, no-wrap
msgid ""
"@Liveness\n"
"@ApplicationScoped\n"
"public class MyStreamingPipeline implements HealthCheck {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:184
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:254
#, no-wrap
msgid "    // ...\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:192
#, no-wrap
msgid ""
"    @Override\n"
"    public HealthCheckResponse call() {\n"
"        return HealthCheckResponse.named(\"My Pipeline\")\n"
"                .state(streams.state().isRunning())\n"
"                .build();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:196
#, fuzzy
msgid "This will expose a health check via HTTP under `/health/live`, which when queried will yield a response like this:"
msgstr "Esto expondrá una comprobación de salud a través de HTTP bajo `/health/live`, que cuando se consulte dará una respuesta como esta:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:204
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 144\n"
"Content-Type: application/json;charset=UTF-8\n"
"Date: Wed, 26 Jun 2019 10:08:36 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:214
#, no-wrap
msgid ""
"{\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"My Pipeline\",\n"
"            \"status\": \"UP\"\n"
"        }\n"
"    ],\n"
"    \"status\": \"UP\"\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:221
#, fuzzy
msgid "When using a container orchestrator such as Kubernetes, you could then set up a https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[liveness probe] for this endpoint.  If the health check fails (i.e. the streaming pipeline is not in the running state), it will return an HTTP 503 response.  This would be the indicator to the orchestrator to restart the pod of this application."
msgstr "Cuando se utiliza un orquestador de contenedores como Kubernetes, se puede configurar una  link:https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[sonda de vida] para este punto final. Si la comprobación de salud falla (es decir, la tubería de streaming no está en estado de ejecución), devolverá una respuesta HTTP 503. Este sería el indicador para que el orquestador reinicie el pod de esta aplicación."

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:222
#, fuzzy, no-wrap
msgid "Metrics"
msgstr "Métrica"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:228
#, fuzzy
msgid "While a health check provides simple means of finding out whether the application is in a state where it can handle requests/messages or not, it is desirable to have more insight into the behaviour of the service.  E.g. it might be of interest to see how many messages have been processed by the streaming pipeline, what's the arrival rate of messages, what's the average processing time and much more."
msgstr "Mientras que una comprobación de la salud proporciona medios sencillos para averiguar si la aplicación está en un estado en el que puede manejar solicitudes/mensajes o no, es deseable tener más información sobre el comportamiento del servicio. Por ejemplo, podría ser interesante ver cuántos mensajes han sido procesados por el canal de streaming, cuál es la tasa de llegada de mensajes, cuál es el tiempo medio de procesamiento y mucho más."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:233
#, fuzzy
msgid "Kafka Streams comes with https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[rich metrics] capabilities which can help to answer these questions.  Using the MicroProfile Metrics API, these metrics can be exposed via HTTP.  From there they can be scraped by tools such as https://prometheus.io/[Prometheus] and eventually be fed to dashboard solutions such as https://grafana.com/[Grafana].  Note that exposing metrics via HTTP instead of JMX has the advantage that this also works when running the application in native mode via GraalVM."
msgstr "Kafka Streams viene con  link:https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[ricas] capacidades de  link:https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[métricas] que pueden ayudar a responder estas preguntas. Mediante la API de métricas de MicroProfile, estas métricas pueden exponerse a través de HTTP. A partir de ahí, se pueden extraer mediante herramientas como  link:https://prometheus.io/[Prometheus] y, finalmente, alimentar soluciones de panel de control como  link:https://grafana.com/[Grafana]. Tenga en cuenta que la exposición de las métricas a través de HTTP en lugar de JMX tiene la ventaja de que esto también funciona cuando se ejecuta la aplicación en modo nativo a través de GraalVM."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:235
#, fuzzy
msgid "Similar to the health check case, just a bit of glue code is needed for exposing the metrics:"
msgstr "Al igual que en el caso de la comprobación de la salud, sólo se necesita un poco de código para exponer las métricas:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:243
#, no-wrap
msgid ""
"    @Inject\n"
"    MetricRegistry metricRegistry;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:248
#, no-wrap
msgid ""
"    void onStart(@Observes StartupEvent event) {\n"
"        // ...\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:252
#, no-wrap
msgid ""
"        streams.start();\n"
"        exportMetrics();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:257
#, no-wrap
msgid ""
"    private void exportMetrics() {\n"
"        Set<String> processed = new HashSet<>();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:261
#, no-wrap
msgid ""
"        for (Metric metric : streams.metrics().values()) {                // <1>\n"
"            String name = metric.metricName().group() +\n"
"                    \":\" + metric.metricName().name();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:265
#, no-wrap
msgid ""
"            if (processed.contains(name)) {\n"
"                continue;\n"
"            }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:277
#, no-wrap
msgid ""
"            // string-typed metric not supported\n"
"            if (name.contentEquals(\"app-info:commit-id\") ||               // <2>\n"
"                    name.contentEquals(\"app-info:version\")) {\n"
"                continue;\n"
"            }\n"
"            else if (name.endsWith(\"count\") || name.endsWith(\"total\")) {  // <3>\n"
"                registerCounter(metric, name);\n"
"            }\n"
"            else {\n"
"                registerGauge(metric, name);                              // <4>\n"
"            }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:281
#, no-wrap
msgid ""
"            processed.add(name);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:285
#, no-wrap
msgid ""
"    private void registerGauge(Metric metric, String name) {\n"
"        Metadata metadata = new Metadata(name, MetricType.GAUGE);\n"
"        metadata.setDescription(metric.metricName().description());\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:287
#, no-wrap
msgid "        metricRegistry.register(metadata, new Gauge<Double>() {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:294
#, no-wrap
msgid ""
"            @Override\n"
"            public Double getValue() {\n"
"                return (Double) metric.metricValue();\n"
"            }\n"
"        } );\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:299
#, no-wrap
msgid ""
"    private void registerCounter(Metric metric, String name) {\n"
"        // ...\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:301
#, fuzzy
msgid "Process all Kafka Streams metrics, using a unique name to register them"
msgstr "Procesar todas las métricas de Kafka Streams, utilizando un nombre único para registrarlas"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:302
#, fuzzy
msgid "Some string-typed \"metrics\" must be excluded"
msgstr "Algunas \"métricas\" de tipo cadena deben ser excluidas"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:303
#, fuzzy
msgid "All metrics whose name ends with \"total\" or \"counter\" will be exposed as counter-typed metrics"
msgstr "Todas las métricas cuyo nombre termine en \"total\" o \"contador\" se expondrán como métricas de tipo contador"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:304
#, fuzzy
msgid "All other metrics will be exposed as gauge-typed metrics, i.e. plain numeric values"
msgstr "El resto de las métricas se expondrán como métricas de tipo gauge, es decir, valores numéricos simples"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:307
#, fuzzy
msgid "Once the application is started, the metrics will be exposed under `/metrics`, returning the data in the OpenMetrics format by default:"
msgstr "Una vez iniciada la aplicación, las métricas se expondrán en `/metrics`, devolviendo los datos en el formato OpenMetrics por defecto:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:317
#, no-wrap
msgid ""
"# HELP application:stream_metrics_process_total The total number of occurrence of process operations.\n"
"# TYPE application:stream_metrics_process_total counter\n"
"application:stream_metrics_process_total 2866.0\n"
"# HELP application:stream_metrics_poll_latency_avg The average latency of poll operation.\n"
"# TYPE application:stream_metrics_poll_latency_avg gauge\n"
"application:stream_metrics_poll_latency_avg 83.3135593220339\n"
"# ...\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:323
#, fuzzy
msgid "From here it's a matter of minutes to set up Prometheus to scrape this target, configure a Prometheus data source in Grafana and configure a dashboard for visualizing the metrics of interest to you.  E.g. the following shows a simple dashboard displaying the poll/process/commit rates and latencies as well as the total number of processed events in the quickstart example:"
msgstr "A partir de aquí, es cuestión de minutos configurar Prometheus para raspar este objetivo, configurar una fuente de datos de Prometheus en Grafana y configurar un cuadro de mando para visualizar las métricas que te interesan. Por ejemplo, a continuación se muestra un panel sencillo que muestra las tasas de sondeo/proceso/comisión y las latencias, así como el número total de eventos procesados en el ejemplo de inicio rápido:"

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:324
#, fuzzy, no-wrap
msgid "Kafka Streams metrics in Grafana"
msgstr "Métricas de Kafka Streams en Grafana"

#. type: Target for macro image
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:324
#, no-wrap
msgid "/assets/images/kafka-streams-metrics.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:326
#, fuzzy, no-wrap
msgid "Summary and Outlook"
msgstr "Resumen y perspectivas"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:332
#, fuzzy
msgid "Quarkus and Eclipse MicroProfile are a great basis for building Kafka Streams applications.  The Quarkus extension for Kafka Streams comes with everything needed to run stream processing pipelines on the JVM as well as in native mode via GraalVM.  The MicroProfile APIs for health checks and metrics can be used to expose the right information for gaining insight into running stream processing applications."
msgstr "Quarkus y Eclipse MicroProfile son una gran base para construir aplicaciones de Kafka Streams. La extensión de Quarkus para Kafka Streams viene con todo lo necesario para ejecutar pipelines de procesamiento de flujos en la JVM, así como en modo nativo a través de GraalVM. Las APIs de MicroProfile para las comprobaciones de salud y las métricas se pueden utilizar para exponer la información adecuada para obtener información sobre la ejecución de las aplicaciones de procesamiento de flujos."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:336
#, fuzzy
msgid "Going forward, we plan to further reduce the efforts needed for building Kafka Streams applications on Quarkus.  Instead of having to deal with the lifecycle of the pipeline yourself, it should be enough to declare a CDI producer method returning the streaming `Topology`:"
msgstr "En el futuro, planeamos reducir aún más los esfuerzos necesarios para construir aplicaciones de Kafka Streams en Quarkus. En lugar de tener que lidiar con el ciclo de vida de la tubería usted mismo, debería ser suficiente declarar un método productor CDI que devuelva el streaming `Topology`:"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:344
#, no-wrap
msgid ""
"@Produces\n"
"public Topology buildTopology()  {\n"
"    // set up the stream topology\n"
"    StreamsBuilder builder = new StreamsBuilder();\n"
"    // builder.stream(...)\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:347
#, no-wrap
msgid ""
"    return builder.build();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:353
#, fuzzy
msgid "This means you'll be able to focus on implementing the actual pipeline logic, while the Quarkus extension would take care of everything else: configuring Kafka Streams based on the Quarkus `application.properties` file, starting the pipeline and automatically exposing healthchecks and metrics."
msgstr "Esto significa que podrás centrarte en la implementación de la lógica real del pipeline, mientras que la extensión de Quarkus se encargaría de todo lo demás: configurar Kafka Streams basándose en el archivo de Quarkus `application.properties`, iniciar el pipeline y exponer automáticamente las comprobaciones de salud y las métricas."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:357
#, fuzzy
msgid "In case this sounds interesting to you, have an eye on the next Quarkus release announcements, as this improved functionality should be out soon.  If you got any related ideas, let us know and join the discussion in Quarkus issue https://github.com/quarkusio/quarkus/issues/2863[#2863]."
msgstr "Si esto le parece interesante, esté atento a los anuncios de la próxima versión de Quarkus, ya que esta funcionalidad mejorada debería salir pronto. Si tienes alguna idea relacionada, háznoslo saber y únete a la discusión en el  link:https://github.com/quarkusio/quarkus/issues/2863[número 2863 de] Quarkus."

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:361
#, fuzzy
msgid "To learn more about the Quarkus extension for Kafka Streams and its current capabilities, check out link:/guides/kafka-streams[the detailed guide].  It not only discusses the actual stream pipeline implementation, but also touches on building (distributed) interactive queries for exposing the current processing state via REST."
msgstr "Para aprender más sobre la extensión de Quarkus para Kafka Streams y sus capacidades actuales, revisa  link:/guides/kafka-streams[la guía detallada]. No solo se habla de la implementación real de la canalización de flujos, sino que también se aborda la creación de consultas interactivas (distribuidas) para exponer el estado de procesamiento actual a través de REST."

#, fuzzy
#~ msgid "---\n"
#~ msgstr "---\n"
